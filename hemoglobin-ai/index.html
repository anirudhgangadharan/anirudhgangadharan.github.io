<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>HemoglobinAI â€” Smartphone-Based Non-Invasive Hemoglobin Estimation</title>
    <meta name="description" content="Smartphone-based ML pipeline for non-invasive hemoglobin estimation in 600 pregnant women, comparing palpebral conjunctiva and buccal mucosa imaging.">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link href="https://fonts.googleapis.com/css2?family=Source+Serif+4:ital,opsz,wght@0,8..60,300;0,8..60,400;0,8..60,600;0,8..60,700;1,8..60,400&family=JetBrains+Mono:wght@400;500&family=Source+Sans+3:wght@300;400;500;600&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg: #fafaf8;
            --surface: #ffffff;
            --text: #1a1a1a;
            --text-secondary: #555;
            --text-tertiary: #888;
            --accent: #0e4f6e;
            --accent-light: #e8f2f8;
            --accent-warm: #c4553a;
            --border: #e2e0dc;
            --border-light: #f0eeea;
            --serif: 'Source Serif 4', 'Georgia', serif;
            --sans: 'Source Sans 3', 'Helvetica Neue', sans-serif;
            --mono: 'JetBrains Mono', monospace;
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: var(--sans); background: var(--bg); color: var(--text); line-height: 1.7; font-size: 16px; -webkit-font-smoothing: antialiased; }

        .topbar { position: fixed; top: 0; left: 0; right: 0; z-index: 100; background: rgba(250,250,248,0.92); backdrop-filter: blur(12px); border-bottom: 1px solid var(--border-light); padding: 0.75rem 2rem; display: flex; justify-content: space-between; align-items: center; font-size: 0.82rem; }
        .topbar a { color: var(--text-secondary); text-decoration: none; font-weight: 500; letter-spacing: 0.02em; }
        .topbar a:hover { color: var(--accent); }
        .topbar-right { display: flex; gap: 1.5rem; }

        .hero { max-width: 860px; margin: 0 auto; padding: 7rem 2rem 3rem; }
        .hero-label { font-family: var(--mono); font-size: 0.72rem; font-weight: 500; color: var(--accent); letter-spacing: 0.12em; text-transform: uppercase; margin-bottom: 1.5rem; }
        .hero h1 { font-family: var(--serif); font-size: 2.4rem; font-weight: 700; line-height: 1.15; color: var(--text); margin-bottom: 0.5rem; letter-spacing: -0.02em; }
        .hero-subtitle { font-family: var(--serif); font-size: 1.1rem; font-weight: 300; color: var(--text-secondary); font-style: italic; margin-bottom: 2rem; }
        .authors { font-size: 0.92rem; color: var(--text-secondary); margin-bottom: 0.5rem; line-height: 1.6; }
        .authors strong { font-weight: 600; color: var(--text); }
        .affiliation { font-size: 0.82rem; color: var(--text-tertiary); margin-bottom: 2rem; }

        .metrics-bar { display: grid; grid-template-columns: repeat(4,1fr); gap: 1px; background: var(--border); border: 1px solid var(--border); border-radius: 6px; overflow: hidden; margin: 2.5rem 0; }
        .metric-cell { background: var(--surface); padding: 1.25rem 1rem; text-align: center; }
        .metric-value { font-family: var(--mono); font-size: 1.6rem; font-weight: 500; color: var(--accent); line-height: 1.2; }
        .metric-label { font-size: 0.72rem; color: var(--text-tertiary); text-transform: uppercase; letter-spacing: 0.08em; margin-top: 0.35rem; }

        .content { max-width: 860px; margin: 0 auto; padding: 0 2rem; }
        .section { margin-bottom: 3.5rem; }
        .section-label { font-family: var(--mono); font-size: 0.68rem; font-weight: 500; color: var(--text-tertiary); letter-spacing: 0.12em; text-transform: uppercase; margin-bottom: 0.75rem; padding-bottom: 0.5rem; border-bottom: 1px solid var(--border-light); }
        .section h2 { font-family: var(--serif); font-size: 1.5rem; font-weight: 600; margin-bottom: 1rem; color: var(--text); }
        .section p { font-size: 0.95rem; color: var(--text-secondary); margin-bottom: 1rem; line-height: 1.8; }

        .pipeline-step-card { display: grid; grid-template-columns: 52px 1fr; gap: 1.25rem; margin-bottom: 1.5rem; align-items: start; }
        .step-number { width: 52px; height: 52px; border-radius: 50%; background: var(--accent); color: #fff; font-family: var(--mono); font-size: 1rem; font-weight: 500; display: flex; align-items: center; justify-content: center; flex-shrink: 0; }
        .step-content h3 { font-family: var(--serif); font-size: 1.1rem; font-weight: 600; margin-bottom: 0.3rem; color: var(--text); }
        .step-content p { font-size: 0.88rem; color: var(--text-secondary); line-height: 1.7; margin-bottom: 0; }

        .screenshot-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; margin: 2rem 0; }
        .screenshot { background: var(--surface); border: 1px solid var(--border); border-radius: 6px; overflow: hidden; }
        .screenshot img { width: 100%; display: block; }
        .screenshot-caption { padding: 0.6rem 0.8rem; font-size: 0.75rem; color: var(--text-tertiary); border-top: 1px solid var(--border-light); text-align: center; }

        .figure { background: var(--surface); border: 1px solid var(--border); border-radius: 6px; overflow: hidden; margin: 2rem 0; }
        .figure img { width: 100%; display: block; }
        .figure-caption { padding: 0.75rem 1rem; font-size: 0.8rem; color: var(--text-secondary); border-top: 1px solid var(--border-light); line-height: 1.5; }
        .figure-caption strong { color: var(--text); font-weight: 600; }

        .results-table-wrap { overflow-x: auto; margin: 1.5rem 0; }
        .results-table { width: 100%; border-collapse: collapse; font-size: 0.85rem; }
        .results-table th { background: var(--accent); color: #fff; padding: 0.7rem 1rem; text-align: left; font-family: var(--mono); font-size: 0.72rem; font-weight: 500; letter-spacing: 0.06em; text-transform: uppercase; }
        .results-table td { padding: 0.6rem 1rem; border-bottom: 1px solid var(--border-light); color: var(--text-secondary); }
        .results-table tr:hover td { background: var(--accent-light); }
        .results-table .best { font-weight: 600; color: var(--accent); }

        .callout { background: var(--accent-light); border-left: 3px solid var(--accent); padding: 1.25rem 1.5rem; margin: 1.5rem 0; border-radius: 0 6px 6px 0; }
        .callout p { font-size: 0.92rem; color: var(--accent); margin: 0; font-weight: 500; line-height: 1.6; }

        .callout-honest { background: #fef8f0; border-left: 3px solid var(--accent-warm); padding: 1.25rem 1.5rem; margin: 1.5rem 0; border-radius: 0 6px 6px 0; }
        .callout-honest p { font-size: 0.92rem; color: #7a3a22; margin: 0; font-weight: 500; line-height: 1.6; }

        .demo-cta { background: var(--surface); border: 2px solid var(--accent); border-radius: 8px; padding: 2rem; text-align: center; margin: 2.5rem 0; }
        .demo-cta h3 { font-family: var(--serif); font-size: 1.2rem; font-weight: 600; margin-bottom: 0.5rem; color: var(--text); }
        .demo-cta p { font-size: 0.88rem; color: var(--text-secondary); margin-bottom: 1.25rem; }
        .demo-cta a { display: inline-block; background: var(--accent); color: #fff; padding: 0.7rem 2rem; border-radius: 5px; text-decoration: none; font-family: var(--mono); font-size: 0.82rem; font-weight: 500; letter-spacing: 0.04em; }
        .demo-cta a:hover { background: #0a3c54; }

        .accuracy-grid { display: grid; grid-template-columns: repeat(4,1fr); gap: 1px; background: var(--border); border: 1px solid var(--border); border-radius: 6px; overflow: hidden; margin: 1.5rem 0; }
        .accuracy-cell { background: var(--surface); padding: 1rem 0.75rem; text-align: center; }
        .accuracy-value { font-family: var(--mono); font-size: 1.3rem; font-weight: 500; color: var(--accent); }
        .accuracy-label { font-size: 0.68rem; color: var(--text-tertiary); text-transform: uppercase; letter-spacing: 0.06em; margin-top: 0.25rem; }

        .innovation { background: var(--surface); border: 1px solid var(--border); border-radius: 6px; padding: 1.5rem; margin: 2rem 0; }
        .innovation-title { font-family: var(--mono); font-size: 0.72rem; font-weight: 500; color: var(--accent-warm); letter-spacing: 0.1em; text-transform: uppercase; margin-bottom: 0.5rem; }
        .innovation p { font-family: var(--serif); font-size: 1.05rem; color: var(--text); font-style: italic; line-height: 1.7; margin: 0; }

        .footer { max-width: 860px; margin: 4rem auto 0; padding: 2rem; border-top: 1px solid var(--border-light); display: flex; justify-content: space-between; align-items: flex-start; font-size: 0.82rem; color: var(--text-tertiary); padding-bottom: 3rem; }
        .footer a { color: var(--accent); text-decoration: none; }
        .footer a:hover { text-decoration: underline; }
        .footer-links { display: flex; flex-direction: column; gap: 0.4rem; text-align: right; }

        @media (max-width: 700px) {
            .hero h1 { font-size: 1.8rem; }
            .metrics-bar, .accuracy-grid { grid-template-columns: repeat(2,1fr); }
            .screenshot-grid { grid-template-columns: 1fr; }
            .footer { flex-direction: column; gap: 1rem; }
            .footer-links { text-align: left; }
        }
    </style>
</head>
<body>

    <nav class="topbar">
        <a href="https://anirudhgangadharan.github.io/">&#8592; Anirudh Gangadharan</a>
        <div class="topbar-right">
            <a href="https://huggingface.co/spaces/medtechdev/anemia-screening" target="_blank">Live Demo</a>
            <a href="https://github.com/anirudhgangadharan" target="_blank">GitHub</a>
        </div>
    </nav>

    <header class="hero">
        <div class="hero-label">Clinical Study &middot; Maternal Health &middot; AI</div>
        <h1>HemoglobinAI</h1>
        <div class="hero-subtitle">Smartphone-Based Machine Learning Pipeline for Non-Invasive Hemoglobin Estimation &mdash; Comparative Performance of Palpebral Conjunctiva and Buccal Mucosa in 600 Pregnant Women</div>

        <div class="authors">
            <strong>Anirudh Gangadharan</strong> &amp; collaborators
        </div>
        <div class="affiliation">
            KHPIMS, Gadag, Karnataka &middot; Cross-sectional study &middot; n = 600
        </div>

        <div class="metrics-bar">
            <div class="metric-cell">
                <div class="metric-value">600</div>
                <div class="metric-label">Pregnant Women</div>
            </div>
            <div class="metric-cell">
                <div class="metric-value">1.018</div>
                <div class="metric-label">Best MAE (g/dL)</div>
            </div>
            <div class="metric-cell">
                <div class="metric-value">0.610</div>
                <div class="metric-label">AUC-ROC</div>
            </div>
            <div class="metric-cell">
                <div class="metric-value">7</div>
                <div class="metric-label">ML Models Tested</div>
            </div>
        </div>
    </header>

    <main class="content">

        <section class="section">
            <div class="section-label">The Problem</div>
            <p>
                Anaemia in pregnancy remains a critical public health challenge in India, affecting nearly 50% of pregnant women and contributing directly to maternal and neonatal mortality. The gold standard &mdash; laboratory haemoglobin measurement &mdash; requires venipuncture, trained phlebotomists, and laboratory infrastructure, making frequent monitoring infeasible in resource-limited settings.
            </p>
            <p>
                In rural primary health centres and community outreach camps, the choice is often binary: perform invasive testing (expensive, slow, requires cold chain) or rely on clinical pallor assessment (subjective, sensitivity &lt;60%). A non-invasive, smartphone-based screening tool could bridge this gap, enabling community health workers to triage pregnant women for anaemia without drawing blood.
            </p>
        </section>

        <section class="section">
            <div class="section-label">Pipeline</div>

            <div class="pipeline-step-card">
                <div class="step-number">1</div>
                <div class="step-content">
                    <h3>Standardised Image Capture</h3>
                    <p>Smartphone photographs of the palpebral conjunctiva (required) and buccal mucosa (optional) are captured alongside a colour calibration card with known colour patches, enabling white-balance normalisation across different smartphones and lighting conditions.</p>
                </div>
            </div>

            <div class="pipeline-step-card">
                <div class="step-number">2</div>
                <div class="step-content">
                    <h3>YOLOv8 Region-of-Interest Segmentation</h3>
                    <p>A fine-tuned YOLOv8 model automatically segments conjunctival or mucosal tissue from surrounding anatomy, isolating the diagnostically relevant region. Calibration card patches are simultaneously detected for colour normalisation.</p>
                </div>
            </div>

            <div class="pipeline-step-card">
                <div class="step-number">3</div>
                <div class="step-content">
                    <h3>Multi-Modal Feature Extraction</h3>
                    <p>Image features (mean RGB, colour histograms, texture metrics) are combined with 52 sociodemographic and clinical features: age, dietary patterns, obstetric history, and medical history &mdash; yielding a 61-feature vector per patient (70 when both sites are combined).</p>
                </div>
            </div>

            <div class="pipeline-step-card">
                <div class="step-number">4</div>
                <div class="step-content">
                    <h3>ML Model Ensemble &amp; Prediction</h3>
                    <p>Seven algorithms (Ridge, Lasso, ElasticNet, SVR, Random Forest, Gradient Boosting, XGBoost) are evaluated with 5-fold cross-validation. The model outputs a continuous haemoglobin estimate (g/dL) with severity classification.</p>
                </div>
            </div>

            <div class="screenshot-grid">
                <div class="screenshot">
                    <img src="screenshot1_conjunctiva.png" alt="Conjunctival image capture with colour calibration card">
                    <div class="screenshot-caption">Conjunctival capture + demographics</div>
                </div>
                <div class="screenshot">
                    <img src="screenshot2_buccal.png" alt="Buccal mucosa capture and medical history">
                    <div class="screenshot-caption">Buccal mucosa + medical history</div>
                </div>
                <div class="screenshot">
                    <img src="screenshot3_obstetric.png" alt="Obstetric history input">
                    <div class="screenshot-caption">Obstetric history input</div>
                </div>
                <div class="screenshot">
                    <img src="screenshot4_result.png" alt="Estimated hemoglobin result">
                    <div class="screenshot-caption">Result: Hb 11.4 g/dL &mdash; Mild Anaemia</div>
                </div>
            </div>
        </section>

        <div class="demo-cta">
            <h3>Try the Live Demo</h3>
            <p>Upload a conjunctival image, enter clinical parameters, and receive an instant haemoglobin estimate.</p>
            <a href="https://huggingface.co/spaces/medtechdev/anemia-screening" target="_blank">Open on HuggingFace &#8594;</a>
        </div>

        <section class="section">
            <div class="section-label">Results</div>
            <p>
                Among 600 pregnant women (mean age 25.34 &plusmn; 3.89 years), 32.17% were primigravida and 39.2% were anaemic by laboratory confirmation. Palpebral conjunctiva imaging with Random Forest regression achieved the best overall performance.
            </p>

            <div class="callout">
                <p>Best model: Random Forest on palpebral conjunctiva &mdash; MAE = 1.018 g/dL, AUC-ROC = 0.610, with 57.3% of predictions within &plusmn;1.0 g/dL of laboratory values.</p>
            </div>

            <p style="font-family: var(--mono); font-size: 0.72rem; color: var(--text-tertiary); letter-spacing: 0.08em; text-transform: uppercase; margin-top: 2rem; margin-bottom: 0.75rem;">Clinical Accuracy &mdash; Palpebral Conjunctiva</p>
            <div class="accuracy-grid">
                <div class="accuracy-cell">
                    <div class="accuracy-value">32.5%</div>
                    <div class="accuracy-label">&plusmn; 0.5 g/dL</div>
                </div>
                <div class="accuracy-cell">
                    <div class="accuracy-value">57.3%</div>
                    <div class="accuracy-label">&plusmn; 1.0 g/dL</div>
                </div>
                <div class="accuracy-cell">
                    <div class="accuracy-value">76.2%</div>
                    <div class="accuracy-label">&plusmn; 1.5 g/dL</div>
                </div>
                <div class="accuracy-cell">
                    <div class="accuracy-value">87.8%</div>
                    <div class="accuracy-label">&plusmn; 2.0 g/dL</div>
                </div>
            </div>

            <p style="font-family: var(--mono); font-size: 0.72rem; color: var(--text-tertiary); letter-spacing: 0.08em; text-transform: uppercase; margin-top: 2rem; margin-bottom: 0.75rem;">Site Comparison (Random Forest)</p>
            <div class="results-table-wrap">
                <table class="results-table">
                    <thead>
                        <tr>
                            <th>Imaging Site</th>
                            <th>MAE (g/dL)</th>
                            <th>R&sup2;</th>
                            <th>AUC-ROC</th>
                            <th>Sensitivity</th>
                            <th>Specificity</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td class="best">Palpebral Conjunctiva</td>
                            <td class="best">1.018</td>
                            <td>0.022</td>
                            <td class="best">0.610</td>
                            <td>0.557</td>
                            <td>0.608</td>
                        </tr>
                        <tr>
                            <td>Buccal Mucosa</td>
                            <td>1.039</td>
                            <td>0.014</td>
                            <td>0.593</td>
                            <td>0.536</td>
                            <td>0.627</td>
                        </tr>
                        <tr>
                            <td>Combined</td>
                            <td>1.028</td>
                            <td>0.017</td>
                            <td>0.599</td>
                            <td>0.549</td>
                            <td>0.600</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="figure">
                <img src="performance_comparison.png" alt="Performance comparison across imaging sites and models">
                <div class="figure-caption">
                    <strong>Figure 1.</strong> Performance comparison across imaging sites and ML models. Palpebral conjunctiva shows marginally superior AUC-ROC and lower MAE. SVR achieved highest AUC-ROC (0.636) while Random Forest achieved lowest MAE (1.018 g/dL).
                </div>
            </div>

            <div class="callout-honest">
                <p><strong>Honest assessment:</strong> The low R&sup2; values (0.014&ndash;0.022) indicate that the current pipeline explains very little variance in haemoglobin levels. The primary contributions are the validated 600-patient paired dataset, the end-to-end pipeline infrastructure, and the comparative evidence that conjunctival imaging outperforms buccal mucosa. These represent a foundation for deeper architectures, not a deployment-ready diagnostic.</p>
            </div>
        </section>

        <section class="section">
            <div class="section-label">Clinical Significance</div>
            <p>
                Despite modest model performance, the contribution is infrastructural. This work establishes a reproducible, colour-calibrated capture protocol replicable across any smartphone; a curated dataset of 600 paired image&ndash;laboratory observations from a real clinical cohort; and evidence that palpebral conjunctiva provides a stronger imaging signal than buccal mucosa, guiding future research toward the more informative anatomical site.
            </p>
            <p>
                In the context of postpartum haemorrhage triage, where any haemoglobin estimate &mdash; even approximate &mdash; outperforms having no information at all, a screening tool with MAE of ~1 g/dL could differentiate severe anaemia from normal levels, enabling triage decisions that currently rely on subjective pallor assessment alone.
            </p>
        </section>

        <div class="innovation">
            <div class="innovation-title">Dataset &amp; Infrastructure Contribution</div>
            <p>
                600 standardised, colour-calibrated smartphone images paired with laboratory haemoglobin values from pregnant women in a resource-limited Indian clinical setting &mdash; a dataset designed for foundation model fine-tuning and transfer learning that could substantially improve on the classical ML baseline reported here.
            </p>
        </div>

        <section class="section">
            <div class="section-label">Ongoing &amp; Future Work</div>
            <p>
                The immediate next step is applying pretrained medical vision foundation models (BiomedCLIP, PubMedCLIP) via transfer learning, replacing handcrafted colour features with deep learned representations. We are also exploring whether a vision transformer fine-tuned on conjunctival images alone &mdash; without sociodemographic features &mdash; can outperform the current multi-modal pipeline, simplifying deployment to a single-photo screening tool.
            </p>
            <p>
                Longer-term goals include multi-site validation across diverse populations and smartphone hardware, integration with the COGNIT semantic protocol for real-time triage transmission, and a prospective clinical trial comparing smartphone-based screening against standard laboratory testing in community health worker settings.
            </p>
        </section>
    </main>

    <footer class="footer">
        <div>
            <div>&copy; 2025 Gangadharan et al.</div>
            <div style="margin-top: 0.25rem;">Contact: <a href="mailto:gangadharananirudh@gmail.com">gangadharananirudh@gmail.com</a></div>
        </div>
        <div class="footer-links">
            <a href="https://anirudhgangadharan.github.io/">Portfolio</a>
            <a href="https://huggingface.co/spaces/medtechdev/anemia-screening">Live Demo</a>
            <a href="https://github.com/anirudhgangadharan">GitHub</a>
        </div>
    </footer>

</body>
</html>
